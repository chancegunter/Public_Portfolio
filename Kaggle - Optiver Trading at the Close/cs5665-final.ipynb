{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Final Project Collaboration CS 5665","metadata":{"id":"3I33SjchIZ-J"}},{"cell_type":"markdown","source":"The purpose of this document is to share code and work on the project simultaniously. Please use the sections and text features to explain what you are doing and how it is applicable to the project.","metadata":{"id":"uRb_un8XIgXa"}},{"cell_type":"markdown","source":"## Imports ...\n","metadata":{"id":"WNkRIpykds7Y"}},{"cell_type":"code","source":"import os\nimport re\n# import io\n# import zipfile\n# import kaggle\nimport numpy as np\nimport pandas as pd\n# from kaggle.api.kaggle_api_extended import KaggleApi\nfrom pathlib import Path\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n# from sklearn.naive_bayes import GaussianNB\n# import datetime as dt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n# import optiver2023\n# env = optiver2023.make_env()","metadata":{"id":"gHeG6hZgeqp7","executionInfo":{"status":"ok","timestamp":1697171237131,"user_tz":360,"elapsed":7184,"user":{"displayName":"Chance Gunter","userId":"15220369532039577217"}},"outputId":"ce642001-0742-4fdb-e316-86dd3fdab6a6","pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-12-05T21:14:30.757879Z","iopub.execute_input":"2023-12-05T21:14:30.758560Z","iopub.status.idle":"2023-12-05T21:14:33.303401Z","shell.execute_reply.started":"2023-12-05T21:14:30.758524Z","shell.execute_reply":"2023-12-05T21:14:33.302237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n\n# downloads_path = str(Path.home() / \"Downloads\")\n# api = KaggleApi()\n# api.authenticate()\n\n# api.competition_download_files(\"optiver-trading-at-the-close\",\n#                                path=os.getcwd())\n# api.competition_download_file(\"optiver-trading-at-the-close\",\n#                               \"train.csv\",\n#                                path=os.getcwd())\n\n# with zipfile.ZipFile(\"train.csv.zip\", 'r') as zip_ref:\n#     zip_ref.extractall(path=os.getcwd())\n\n# with zipfile.ZipFile(\"optiver-trading-at-the-close.zip\", 'r') as zip_ref:\n#     zip_ref.extractall(path=os.getcwd())\n\n# data_df = pd.read_csv(\"train.csv\")","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-05T21:14:33.305301Z","iopub.execute_input":"2023-12-05T21:14:33.306184Z","iopub.status.idle":"2023-12-05T21:14:46.985810Z","shell.execute_reply.started":"2023-12-05T21:14:33.306148Z","shell.execute_reply":"2023-12-05T21:14:46.984500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DATA CLEANSING**","metadata":{}},{"cell_type":"code","source":"\nprint(data_df.info())\n# train_df = train_df.drop(columns=['row_id'])\n\n# handle missing values values in train data\ncolumns_to_fill = ['imbalance_size', 'reference_price', 'matched_size', 'bid_price', 'ask_price']\ngrouped_means = data_df.groupby('stock_id')[columns_to_fill].transform('mean')\n\n# Fill NaN values with the grouped means\ndata_df[columns_to_fill] = data_df[columns_to_fill].fillna(grouped_means)\ndata_df.columns\n\n# Define the formula for wap\nwap_formula = (data_df['bid_price'] * data_df['ask_size'] + data_df['ask_price'] * data_df['bid_size']) / (data_df['bid_size'] + data_df['ask_size'])\n\n# Fill missing values in 'wap' using np.where\ndata_df['wap'] = np.where(data_df['wap'].isna(), wap_formula, data_df['wap'])\ndata_df = data_df.dropna()\nprint(data_df.shape)","metadata":{"id":"Tj7nguqCk0cz","executionInfo":{"status":"ok","timestamp":1697171309281,"user_tz":360,"elapsed":35335,"user":{"displayName":"Chance Gunter","userId":"15220369532039577217"}},"outputId":"5e5ad749-1879-428a-d0e4-a1b9a30032d7","pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-12-05T21:14:46.989383Z","iopub.execute_input":"2023-12-05T21:14:46.990478Z","iopub.status.idle":"2023-12-05T21:14:48.102681Z","shell.execute_reply.started":"2023-12-05T21:14:46.990440Z","shell.execute_reply":"2023-12-05T21:14:48.101126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TRIAN TEST SPLIT**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data_df.drop(columns=['target', 'row_id', 'time_id', 'near_price', 'far_price'])\ny = data_df[['target']]\n\n# First split the data into training (80%) and temporary (20%) sets\nX_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2)\n\n# Then split the temporary set into validation (10%) and test (10%) sets\nX_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.5)\n\n# Convert the targets to float\ny_train = y_train['target'].astype('float')\ny_val = y_val['target'].astype('float')\ny_test = y_test['target'].astype('float')","metadata":{"pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-12-05T21:14:48.105212Z","iopub.execute_input":"2023-12-05T21:14:48.105534Z","iopub.status.idle":"2023-12-05T21:14:49.729790Z","shell.execute_reply.started":"2023-12-05T21:14:48.105502Z","shell.execute_reply":"2023-12-05T21:14:49.728313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Error Testing**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\n# Calculate the MAE\n# mae = mean_absolute_error(true_values, predictions)\n\n# print('The Mean Absolute Error of our forecasts is {}'.format(round(mae, 2)))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:14:49.731347Z","iopub.execute_input":"2023-12-05T21:14:49.731650Z","iopub.status.idle":"2023-12-05T21:14:49.737507Z","shell.execute_reply.started":"2023-12-05T21:14:49.731625Z","shell.execute_reply":"2023-12-05T21:14:49.735935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Linear Regression**","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()\nlr_model = lr.fit(X_train, y_train)\nlr_predict = lr_model.predict(X_test)\n\nlr_mae = mean_absolute_error(y_test, lr_predict)\nprint('The Mean Absolute Error of our forecasts is {}'.format(round(lr_mae, 2)))","metadata":{"pycharm":{"is_executing":true},"execution":{"iopub.status.busy":"2023-12-05T21:14:49.739292Z","iopub.execute_input":"2023-12-05T21:14:49.739652Z","iopub.status.idle":"2023-12-05T21:14:50.192891Z","shell.execute_reply.started":"2023-12-05T21:14:49.739617Z","shell.execute_reply":"2023-12-05T21:14:50.191593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MLP MODEL**","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\nmlp = MLPRegressor(hidden_layer_sizes=(5,5,5), activation='identity', max_iter=500)\n\nmlp_model = mlp.fit(X_train, y_train)\nmlp_model.score(X_test, y_test)\nmlp_predict = mlp_model.predict(X_test)\n\nmlp_mae = mean_absolute_error(y_test, mlp_predict)\nprint('The Mean Absolute Error of our forecasts is {}'.format(round(mlp_mae, 2)))","metadata":{"collapsed":false,"pycharm":{"is_executing":true},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-12-05T21:14:50.194394Z","iopub.execute_input":"2023-12-05T21:14:50.194732Z","iopub.status.idle":"2023-12-05T21:16:14.031058Z","shell.execute_reply.started":"2023-12-05T21:14:50.194703Z","shell.execute_reply":"2023-12-05T21:16:14.030329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Cat Boosting**","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor as CBR;\n\ncbr = CBR(objective='MAE',iterations=300, depth=4, learning_rate=.01,l2_leaf_reg=1.4,early_stopping_rounds=15)\ncbr_model = cbr.fit(X_train, y_train)\ncbr_model.score(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:16:14.032484Z","iopub.execute_input":"2023-12-05T21:16:14.033010Z","iopub.status.idle":"2023-12-05T21:16:48.751637Z","shell.execute_reply.started":"2023-12-05T21:16:14.032982Z","shell.execute_reply":"2023-12-05T21:16:48.750503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Tabnet**","metadata":{}},{"cell_type":"code","source":"target = \"target\"\ndata_df.drop(columns=['row_id', 'time_id', 'near_price', 'far_price'], inplace=True)\nn_total = len(data_df)\n\ntrain_val_indices, test_indices = train_test_split(\n    range(n_total), test_size=0.2, random_state=0)\ntrain_indices, valid_indices = train_test_split(\n    train_val_indices, test_size=0.2 / 0.6, random_state=0)\n\ncategorical_columns = []\ncategorical_dims =  {}\nfor col in data_df.columns[data_df.dtypes == object]:\n    print(col, data_df[col].nunique())\n    l_enc = LabelEncoder()\n    data_df[col] = data_df[col].fillna(\"VV_likely\")\n    data_df[col] = l_enc.fit_transform(data_df[col].values)\n    categorical_columns.append(col)\n    categorical_dims[col] = len(l_enc.classes_)\n\nfor col in data_df.columns[data_df.dtypes == 'float64']:\n    data_df.fillna(data_df.loc[train_indices, col].mean(), inplace=True)\n    \nunused_feat = []\n\nfeatures = [ col for col in data_df.columns if col not in unused_feat+[target]] \n\ncat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n\ncat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]","metadata":{"execution":{"iopub.status.busy":"2023-12-05T21:16:48.752887Z","iopub.execute_input":"2023-12-05T21:16:48.753180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch\n!pip install pytorch-tabnet wget\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom sklearn.model_selection import KFold\n# from sklearn.preprocessing import LabelEncoder, MinMaxScalar\nfrom sklearn.metrics import accuracy_score\n\nclf = TabNetClassifier(\n    n_d=64, n_a=64, n_steps=5,\n    gamma=1.5, n_independent=2, n_shared=2,\n    cat_idxs=cat_idxs,\n    cat_dims=cat_dims,\n    cat_emb_dim=1,\n    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    scheduler_params = {\"gamma\": 0.95,\n                     \"step_size\": 20},\n    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n\nif os.getenv(\"CI\", False):\n# Take only a subsample to run CI\n    X_train = train[features].values[train_indices][:1000,:]\n    y_train = train[target].values[train_indices][:1000]\nelse:\n    X_train = train[features].values[train_indices]\n    y_train = train[target].values[train_indices]\n\nX_valid = train[features].values[valid_indices]\ny_valid = train[target].values[valid_indices]\n\nX_test = train[features].values[test_indices]\ny_test = train[target].values[test_indices]\n    \nmax_epochs = 5 if not os.getenv(\"CI\", False) else 2\n    \nclf.fit(\n    X_train=X_train, y_train=y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_name=['train', 'valid'],\n    max_epochs=max_epochs, patience=100,\n    batch_size=16384, virtual_batch_size=256\n) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(clf.history['train']['loss'])\nplt.plot(clf.history['valid']['loss'])\nplt.show()\n\nplt.pltot([-x for x in clf.history['train']['metric']])\nplt.pltot([-x for x in clf.history['valid']['metric']])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = clf.predict_proba(X_test)\ntest_ac = roc_auc_score(y_score=preds[:,1], y_true=y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optiver Dummy Test from Optiver","metadata":{"id":"WqenxyDkpgjh"}},{"cell_type":"markdown","source":"**Baseline**","metadata":{}},{"cell_type":"code","source":"# import optiver2023\n# env = optiver2023.make_env()\n# iter_test = env.iter_test()\n# counter = 0\n# for (test, revealed_targets, sample_prediction) in iter_test:\n#     if counter == 0:\n#         print(test.head(3))\n#         print(revealed_targets.head(3))\n#         print(sample_prediction.head(3))\n#     sample_prediction['target'] = 0\n#     env.predict(sample_prediction)\n#     counter += 1","metadata":{"id":"ltsVy6n_pfU3","executionInfo":{"status":"aborted","timestamp":1697171322331,"user_tz":360,"elapsed":6,"user":{"displayName":"Chance Gunter","userId":"15220369532039577217"}},"pycharm":{"is_executing":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression Submit**","metadata":{}},{"cell_type":"code","source":"# import optiver2023\n# env = optiver2023.make_env()\n# iter_test = env.iter_test()\n# counter = 0\n# for (test, revealed_targets, sample_prediction) in iter_test:\n#     print(test.head(3))\n#     print(revealed_targets.head(3))\n#     print(sample_prediction.head(3))\n#     test = test.drop(columns=['row_id', 'near_price', 'far_price'])\n#     columns_to_fill = ['imbalance_size', 'reference_price', 'matched_size', 'bid_price', 'ask_price']\n#     grouped_means = test.groupby('stock_id')[columns_to_fill].transform('mean')\n\n#     # Fill NaN values with the grouped means\n#     test[columns_to_fill] = test[columns_to_fill].fillna(grouped_means)\n\n#     # Define the formula for wap\n#     wap_formula = (test['bid_price'] * test['ask_size'] + test['ask_price'] * test['bid_size']) / (test['bid_size'] + test['ask_size'])\n\n#     # Fill missing values in 'wap' using np.where\n#     test['wap'] = np.where(test['wap'].isna(), wap_formula, test['wap'])\n#     print(test.isna())\n#     sample_prediction['target'] = lr_model.predict(test)\n#     env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/code/sohier/optiver-2023-basic-submission-demo?cellIds=1&kernelSessionId=144492283","metadata":{"id":"gWOXCaxTpzvP"}},{"cell_type":"markdown","source":"**MLP Submit**","metadata":{}},{"cell_type":"code","source":"# import optiver2023\n# env = optiver2023.make_env()\n# iter_test = env.iter_test()\n# counter = 0\n# for (test, revealed_targets, sample_prediction) in iter_test:\n#     print(test.head(3))\n#     print(revealed_targets.head(3))\n#     print(sample_prediction.head(3))\n#     test = test.drop(columns=['row_id', 'near_price', 'far_price'])\n#     columns_to_fill = ['imbalance_size', 'reference_price', 'matched_size', 'bid_price', 'ask_price']\n#     grouped_means = test.groupby('stock_id')[columns_to_fill].transform('mean')\n\n#     # Fill NaN values with the grouped means\n#     test[columns_to_fill] = test[columns_to_fill].fillna(grouped_means)\n\n#     # Define the formula for wap\n#     wap_formula = (test['bid_price'] * test['ask_size'] + test['ask_price'] * test['bid_size']) / (test['bid_size'] + test['ask_size'])\n\n#     # Fill missing values in 'wap' using np.where\n#     test['wap'] = np.where(test['wap'].isna(), wap_formula, test['wap'])\n#     print(test.isna())\n#     sample_prediction['target'] = mlp.predict(test)\n#     env.predict(sample_prediction)","metadata":{"id":"nFPI9CM-otEO","executionInfo":{"status":"aborted","timestamp":1697171322331,"user_tz":360,"elapsed":5,"user":{"displayName":"Chance Gunter","userId":"15220369532039577217"}},"pycharm":{"is_executing":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cad Boosting Submit**","metadata":{}},{"cell_type":"code","source":"import optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\ncounter = 0\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    print(test.head(3))\n    print(revealed_targets.head(3))\n    print(sample_prediction.head(3))\n    test = test.drop(columns=['row_id','near_price','far_price'])\n    columns_to_fill = ['imbalance_size', 'reference_price', 'matched_size', 'bid_price', 'ask_price']\n    grouped_means = test.groupby('stock_id')[columns_to_fill].transform('mean')\n\n    # Fill NaN values with the grouped means\n    test[columns_to_fill] = test[columns_to_fill].fillna(grouped_means)\n\n    # Define the formula for wap\n    wap_formula = (test['bid_price'] * test['ask_size'] + test['ask_price'] * test['bid_size']) / (test['bid_size'] + test['ask_size'])\n\n    # Fill missing values in 'wap' using np.where\n    test['wap'] = np.where(test['wap'].isna(), wap_formula, test['wap'])\n    print(test.isna())\n    sample_prediction['target'] = cbr.predict(test)\n    env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}